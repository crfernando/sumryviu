{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "sumryvu_v1_bert_vader.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b63d63e9bec462fb03e03ef1178dbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_571a649a71514897bfea179d342f1103",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b515961ef19f44e29f862ff2bc27f78f",
              "IPY_MODEL_c8cb81208ba54cb28886445e77a13de9"
            ]
          }
        },
        "571a649a71514897bfea179d342f1103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b515961ef19f44e29f862ff2bc27f78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_424f91a4611f494a9f83ebfda5523edf",
            "_dom_classes": [],
            "description": "Batches: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 11,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a667d51aaf4433c8f63d478c83862f1"
          }
        },
        "c8cb81208ba54cb28886445e77a13de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f94bef653ab492698d3ea890bc4a425",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11/11 [00:37&lt;00:00,  3.44s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbd8721342544c0c85a1fbd1b7a4dbce"
          }
        },
        "424f91a4611f494a9f83ebfda5523edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a667d51aaf4433c8f63d478c83862f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f94bef653ab492698d3ea890bc4a425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbd8721342544c0c85a1fbd1b7a4dbce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crfernando/sumryviu/blob/dev/sumryvu_v1_bert_vader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gecavTA9_PrC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef01319e-9f99-4109-c368-69d6cbc22ae6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tgu1RR8v-vBl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a1fcd9e-635a-45b5-b6b7-15bf504984d1"
      },
      "source": [
        "!pip install symspellpy\n",
        "!pip install sentence_transformers\n",
        "!pip install hdbscan\n",
        "!pip install vaderSentiment\n",
        "!pip install umap-learn"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: symspellpy in /usr/local/lib/python3.7/dist-packages (6.7.0)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.7/dist-packages (from symspellpy) (1.19.5)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.1.95)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence_transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers) (0.10.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence_transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence_transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence_transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence_transformers) (3.4.1)\n",
            "Requirement already satisfied: hdbscan in /usr/local/lib/python3.7/dist-packages (0.8.27)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.15.0)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (0.22.2.post1)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (0.29.22)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.19.5)\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.7/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Collecting umap-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/69/85e7f950bb75792ad5d666d86c5f3e62eedbb942848e7e3126513af9999c/umap-learn-0.5.1.tar.gz (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/65/8189298dd3a05bbad716ee8e249764ff8800e365d8dc652ad2192ca01b4a/pynndescent-0.5.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (54.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-cp37-none-any.whl size=76569 sha256=5e821f3158eef270bd6003d09f83a8294699ec33e1b9df6c2c4676191af81358\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/df/d5/a3691296ff779f25cd1cf415a3af954b987fb53111e3392cf4\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.2-cp37-none-any.whl size=51351 sha256=97f4cc6787098755b7234d2d555faf74c57175b4ef23fbb5d63c63bcec033601\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/52/4e/4c28d04d144a28f89e2575fb63628df6e6d49b56c5ddd0c74e\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.2 umap-learn-0.5.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "umap"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpa_NXdj_2Gl"
      },
      "source": [
        "import os\n",
        "import pandas as pd; pd.set_option('display.max_colwidth', None)\n",
        "import re\n",
        "import json\n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import strip_tags, strip_non_alphanum, strip_multiple_whitespaces, strip_short, remove_stopwords, split_alphanum, strip_numeric\n",
        "import pkg_resources\n",
        "from symspellpy import SymSpell, Verbosity\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy; nlp = spacy.load('en', disable=['parser', 'ner'])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCGog_JB-vBw"
      },
      "source": [
        "#### Data loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOi7zB16-vBx"
      },
      "source": [
        "def load_data(file_path):\n",
        "    raw_data = pd.read_csv(file_path)\n",
        "    raw_data.columns = map(str.lower, raw_data.columns)\n",
        "    raw_data = raw_data.dropna(subset=['body']) # drop empty or null rows\n",
        "    raw_data = raw_data.drop_duplicates('body') # drop duplicate rows\n",
        "    raw_data = raw_data.groupby('asin').filter(lambda x:len(x) > 780) # get items length over n amount\n",
        "    raw_data = raw_data.query('verified == True') # consider ony verified reviews\n",
        "    raw_data = raw_data[raw_data['body'].str.split().str.len() > 25] # remove review length less than 5\n",
        "    stage_data = raw_data[{'asin', 'body'}].rename(columns={'asin': 'item_id', 'body': 'review_text'}, errors='raise').copy().reset_index(drop=True)\n",
        "    \n",
        "    return stage_data.query(\"item_id == 'B00F2SKPIM'\") # <-- THIS FILTER HAS TO BE REMOVED..."
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhYFCe1B-vBy"
      },
      "source": [
        "def expand_contractions(text, pattern, contraction_map):\n",
        "    '''\n",
        "    this function will expands the contraction of provided text by matching the pattern given\n",
        "        text - sentence, phrase or word for expansion\n",
        "        patter - regex pattern\n",
        "        contraction_map - contraction mapping dictionary\n",
        "    '''\n",
        "    def replace(match):\n",
        "        return contraction_map[match.group(0)]\n",
        "    return pattern.sub(replace, text)\n",
        "\n",
        "def sentence_preprocess(text):\n",
        "    ''' \n",
        "    this function does simple text pre-processing such as, \n",
        "        - remove html tags\n",
        "        - remove non-alphabetic \n",
        "        - remove punctuation\n",
        "        - lowercase\n",
        "    '''\n",
        "    step_process_text = strip_tags(str(text))\n",
        "#     step_process_text = split_alphanum(step_process_text)\n",
        "    step_process_text = strip_numeric(step_process_text)\n",
        "    step_process_text = strip_non_alphanum(step_process_text)\n",
        "    step_process_text = strip_multiple_whitespaces(step_process_text)\n",
        "    step_process_text = strip_short(step_process_text, minsize=2)\n",
        "#     step_process_text = remove_stopwords(step_process_text)\n",
        "    processed_text = step_process_text.strip()\n",
        "    \n",
        "    return processed_text\n",
        "\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=3, prefix_length=7)\n",
        "dictionary_path = pkg_resources.resource_filename(\"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "\n",
        "def tokeninze(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.pos_ in allowed_postags]\n",
        "\n",
        "    for idx, token in enumerate(tokens):\n",
        "        suggestion = sym_spell.lookup(token, Verbosity.CLOSEST, max_edit_distance=3)\n",
        "        if suggestion:\n",
        "            tokens[idx] = suggestion[0].term\n",
        "    \n",
        "    return tokens\n",
        " "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wftn6eo-vBz"
      },
      "source": [
        "work_dir = \"/content/drive/MyDrive/sumryviu/\"\n",
        "data_file = os.path.join(work_dir, \"data/amazon-cell-phone-reviews.csv\")\n",
        "contractions_file = os.path.join(work_dir, \"data/contractions.json\")\n",
        "\n",
        "with open(contractions_file) as file:\n",
        "    contraction_dict = {key.lower(): value.lower() for key, value in json.load(file).items()}\n",
        "\n",
        "re_pattern = re.compile('({})'.format('|'.join(contraction_dict.keys())), flags=re.IGNORECASE)\n",
        "\n",
        "reviews_data = load_data(data_file)\n",
        "reviews_data.index.names = ['row_id']\n",
        "reviews_data = reviews_data.reset_index()\n",
        "reviews_data['processed_review'] = reviews_data['review_text'].str.lower().apply(lambda row: expand_contractions(row, re_pattern, contraction_dict)) # expand contraction\n",
        "reviews_data['processed_review'] = reviews_data['processed_review'].apply(sentence_preprocess)\n",
        "# reviews_data['processed_tokens'] = reviews_data['processed_review'].apply(lambda row: tokeninze(row, allowed_postags=['NOUN', 'VERB', 'ADV']))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H3xYL5dr-vx"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyser = SentimentIntensityAnalyzer()\n",
        "\n",
        "def sentiment_analyzer_scores(sentence):\n",
        "    polarity_scores = analyser.polarity_scores(sentence)\n",
        "    compound_score = polarity_scores['compound']\n",
        "\n",
        "    return compound_score"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcHUX8nE3k21"
      },
      "source": [
        "reviews_data['compound_score'] = reviews_data['processed_review'].apply(sentiment_analyzer_scores)\n",
        "reviews_data['polarity'] = reviews_data['compound_score'].apply(lambda s: \"Positive\" if s > 0 else \"Negative\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p29Yu3-W-vB0"
      },
      "source": [
        "train_review_set, test_review_set = train_test_split(reviews_data, test_size=0.2)\n",
        "data = train_review_set.processed_review.to_numpy()\n",
        "row_id = train_review_set.row_id.to_numpy()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "9b63d63e9bec462fb03e03ef1178dbea",
            "571a649a71514897bfea179d342f1103",
            "b515961ef19f44e29f862ff2bc27f78f",
            "c8cb81208ba54cb28886445e77a13de9",
            "424f91a4611f494a9f83ebfda5523edf",
            "1a667d51aaf4433c8f63d478c83862f1",
            "2f94bef653ab492698d3ea890bc4a425",
            "cbd8721342544c0c85a1fbd1b7a4dbce"
          ]
        },
        "id": "3Q65OxyeUGQa",
        "outputId": "a1beb93c-c660-42fa-f074-ce1a5bc806d5"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import umap\n",
        "import hdbscan\n",
        "\n",
        "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens') #distilbert-base-nli-mean-tokens\n",
        "embeddings = model.encode(data, show_progress_bar=True)\n",
        "reducer = umap.UMAP(n_neighbors=15, n_components=5, metric='cosine').fit_transform(embeddings)\n",
        "cluster = hdbscan.HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom').fit(reducer)\n",
        "# cluster.labels_"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b63d63e9bec462fb03e03ef1178dbea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batches', max=11.0, style=ProgressStyle(description_width…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "IeAXDKYWtUPb",
        "outputId": "d519a565-21da-4150-91ab-d094b47e1508"
      },
      "source": [
        "docs_df = pd.DataFrame(list(zip(row_id, data)), columns=[\"row_id\", \"text\"])\n",
        "docs_df['label'] = cluster.labels_\n",
        "docs_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>547</td>\n",
              "      <td>love this phone however the sim card received did not work so had to go to verizon store to get new sim card</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>423</td>\n",
              "      <td>do not use cell phone lot but love the functionality of this phone it is more like mini tablet the pen that comes with it is very handy and activates the phone when you pull it out it is also great for more precise selections and for note taking am very happy with the resolution of the screen and the response of both touch and pen buying the phone from amazon and setting up new verizon account was painless easily got the account and on line payment set up without hitch also transferred my at phone number to the phone without any problems will not reiterate the tech specs of the phone as you can read all of that on the product page just want to let you know what think of it as user of the phone at this point in time could not be happier with this phone or the verizon service update have had this phone for little over years and still have no desire to get new phone did however recently decide to switch my service provider from verizon to mobile because of the offerings of mobile which will not get into was assured by the mobile rep that as long as the phone was unlocked could replace the verizon sim card with the one from mobile and the phone would work with no problems after activating the mobile sim card am updating this review so that others do not experience what did if they want to change their provider first of all verizon has never locked any of their phones verizon uses cdma network which is also used by sprint and us cellular mobile and at use gsm network one difference is the polarity used so phone for each type of network are manufactured to use the specific polarity of the network the other difference that should be considered by the end user is that on the gsm network customer information is stored on the sim card this means that you can take the sim card from one phone and insert it into another and it will work gsm carriers must accept any gsm phone so they do not have control over the phone you are using cdma carriers use network based white lists so you can only switch phones with your carrier permission and the carrier does not have to accept any particular phone there are other differences between the two network types but those have mentioned affect the end user the most in my case had to buy new phone in order to switch to mobile as carrier was also told by verizon that this phone may work with another cdma carrier but it my lose functionality have had to buy another phone to use the gsm network and have decided to get the galaxy note since have to give up my note hope this helps other in choosing carrier and phone</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>517</td>\n",
              "      <td>bought it as gift and she loves it large screen fast gets updates and since she plays lot of games on it it is exactly what she needs</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>626</td>\n",
              "      <td>when bought work fine but days stopped working you are going to waste your money the only good thing is that amazon helped me get my money back</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>794</td>\n",
              "      <td>phone arrived in time instructions to activate was very simple love my note sometimes have had issues with phone call quality but otherwise the phone is great buy love samsung products</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   row_id  ... label\n",
              "0     547  ...     1\n",
              "1     423  ...     0\n",
              "2     517  ...     0\n",
              "3     626  ...    -1\n",
              "4     794  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFiuevmT5wwx"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def c_tf_idf(documents, m, ngram_range=(2, 2)):\n",
        "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
        "    t = count.transform(documents).toarray()\n",
        "    w = t.sum(axis=1)\n",
        "    tf = np.divide(t.T, w)\n",
        "    sum_t = t.sum(axis=0)\n",
        "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
        "    tf_idf = np.multiply(tf, idf)\n",
        "\n",
        "    return tf_idf, count\n",
        "\n",
        "docs_per_topic = docs_df.groupby(['label'], as_index = False).agg({'text': ' '.join})\n",
        "tf_idf, count = c_tf_idf(docs_per_topic.text.values, m=len(data))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LAYPzzD6Fw3"
      },
      "source": [
        "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n",
        "    words = count.get_feature_names()\n",
        "    labels = list(docs_per_topic.label)\n",
        "    tf_idf_transposed = tf_idf.T\n",
        "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
        "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
        "    return top_n_words\n",
        "\n",
        "def extract_topic_sizes(df):\n",
        "    topic_sizes = (df.groupby(['label'])\n",
        "                     .text\n",
        "                     .count()\n",
        "                     .reset_index()\n",
        "                     .rename({\"label\": \"Topic\", \"text\": \"Size\"}, axis='columns')\n",
        "                     .sort_values(\"Size\", ascending=False))\n",
        "    return topic_sizes    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "oX3Jjh8c6YQF",
        "outputId": "527950d6-3a55-4761-ffe1-7d247ff270bb"
      },
      "source": [
        "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
        "topic_sizes = extract_topic_sizes(docs_df); topic_sizes.head(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Topic  Size\n",
              "0     -1   153\n",
              "1      0   123\n",
              "2      1    56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMrLihaV6lka",
        "outputId": "72f080d0-82e2-4017-a264-eec825785ac7"
      },
      "source": [
        "for i in top_n_words.values():\n",
        "  print(i)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('love phone', 0.00908459117751686),\n",
              " ('battery life', 0.008811919877942697),\n",
              " ('great phone', 0.007432799122504856),\n",
              " ('samsung galaxy', 0.006754165247317133),\n",
              " ('best phone', 0.0061062139052438635)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2AnXou27FS7"
      },
      "source": [
        "# from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# for i in range(20):\n",
        "#     # Calculate cosine similarity\n",
        "#     similarities = cosine_similarity(tf_idf.T)\n",
        "#     np.fill_diagonal(similarities, 0)\n",
        "\n",
        "#     # Extract label to merge into and from where\n",
        "#     topic_sizes = docs_df.groupby(['label']).count().sort_values(\"text\", ascending=False).reset_index()\n",
        "#     topic_to_merge = topic_sizes.iloc[-1].label\n",
        "#     topic_to_merge_into = np.argmax(similarities[topic_to_merge + 1]) - 1\n",
        "\n",
        "#     # Adjust topics\n",
        "#     docs_df.loc[docs_df.label == topic_to_merge, \"Topic\"] = topic_to_merge_into\n",
        "#     old_topics = docs_df.sort_values(\"Topic\").Topic.unique()\n",
        "#     map_topics = {old_topic: index - 1 for index, old_topic in enumerate(old_topics)}\n",
        "#     docs_df.Topic = docs_df.Topic.map(map_topics)\n",
        "#     docs_per_topic = docs_df.groupby(['label'], as_index = False).agg({'text': ' '.join})\n",
        "\n",
        "#     # Calculate new topic words\n",
        "#     m = len(data)\n",
        "#     tf_idf, count = c_tf_idf(docs_per_topic.text.values, m)\n",
        "#     top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
        "\n",
        "# topic_sizes = extract_topic_sizes(docs_df); topic_sizes.head(10)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSg_POTo7xaH"
      },
      "source": [
        "#  sentences = docs_df.head()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnOGiSPIVkSi",
        "outputId": "5da17c6c-e177-4edd-8f55-446ddfade453"
      },
      "source": [
        "# sentences = train_review_set.sample(3).processed_review.values.tolist()\n",
        "sentences_dict = train_review_set.sample(3).set_index('row_id')['processed_review'].to_dict()\n",
        "sentences_dict"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{487: 'without getting all technical if you do not need the latest greatest edge note this thing is powerhouse unto itself am very happy with my decision and for the price with yr contract how could not be',\n",
              " 625: 'twas the day before christmas sat by my tree and opened the amazon box that contained my note the box it was beautiful the phone even more followed the guide to the letter and was online by four downloaded my apps from the great google play christmas had come early on that wonderful day there is so much to learn about this beast of mine will write more about it some other time for now it is just calls and music and text will have to say it is just as good sex',\n",
              " 674: 'works perfectly really clear screen best samsung model phone ever only problem the replacement bezel used in this refurbishment is even cheaper than original samsung one silver paint chips off even when in protective case'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLycrkxZWPxc"
      },
      "source": [
        "# doc = nlp(str(sentences))\n",
        "# tokens = [token.lemma_.strip() for token in doc if not token.is_stop]\n",
        "\n",
        "# def normalize(comment, lowercase, remove_stopwords):\n",
        "#   if lowercase:\n",
        "#       comment = comment.lower()\n",
        "#   comment = nlp(comment)\n",
        "#   lemmatized = []\n",
        "#   for word in comment:\n",
        "#       lemma = word.lemma_.strip()\n",
        "#       if lemma:\n",
        "#           if not remove_stopwords or (remove_stopwords and lemma not in stops):\n",
        "#               lemmatized.append(lemma)\n",
        "#   return \" \".join(lemmatized)\n",
        "\n",
        "token_list = []\n",
        "for sentence in sentences_dict.values():\n",
        "  doc = nlp(sentence)\n",
        "  tokens = [token.lemma_.strip() for token in doc if not token.is_stop]\n",
        "  token_list.append(tokens)\n",
        "\n",
        "from itertools import chain\n",
        "corpus = sorted(set(chain(*token_list)))\n",
        "# corpus\n",
        "\n",
        "# keyword_vect = [1 if token in (\"battery\", \"life\") else 0 for token in corpus]\n",
        "\n",
        "# print(keyword_vect)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM-0SA4L6bAe",
        "outputId": "14a37c51-f36f-491e-f11c-ea65551fcb50"
      },
      "source": [
        "# for i in top_n_words.values():\n",
        "#   for word, *args in i:\n",
        "#     print(word)\n",
        "\n",
        "from itertools import chain\n",
        "# corpus = sorted(set(chain(*token_list)))\n",
        "\n",
        "topic_vect_dict = {}\n",
        "for topic, topic_words in top_n_words.items():\n",
        "  aspects = []\n",
        "  for keywords, score in topic_words:\n",
        "    aspects.append(keywords.split())\n",
        "    aspects_ls = sorted(set(chain(*aspects)))\n",
        "  topic_vect = [1 if token in aspects_ls else 0 for token in corpus]\n",
        "  topic_vect_dict[topic] = topic_vect\n",
        "print(topic_vect_dict)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{-1: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 1: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UznOu2KOf1ga",
        "outputId": "7a255f11-346d-499f-f9d5-75a63e5bb824"
      },
      "source": [
        "# text = 'bought it as gift and she loves it large screen fast gets updates and since she plays lot of games on it it is exactly what she needs'\n",
        "# text_vect = [1 if token in text.split() else 0 for token in corpus]\n",
        "\n",
        "# print(text_vect)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC3ralyb6k8f"
      },
      "source": [
        "sentence_vect_dict = {}\n",
        "for id, sentence in sentences_dict.items():\n",
        "  text_vect = [1 if token in sentence.split() else 0 for token in corpus]\n",
        "  sentence_vect_dict[id] = text_vect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv5bJHhT-PQY",
        "outputId": "eda20d55-b25b-4fd6-d42e-9f90e50171ef"
      },
      "source": [
        "cos_sim = lambda x, y: dot(x,y)/(norm(x)*norm(y))\n",
        "for r_id, s_vec in sentence_vect_dict.items():\n",
        "  print(r_id)\n",
        "  for t_id, t_vec in topic_vect_dict.items():\n",
        "    print('\\t', t_id, cos_sim(s_vec, t_vec))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "674\n",
            "\t -1 0.1951800145897066\n",
            "\t 0 0.3464101615137754\n",
            "\t 1 0.14907119849998599\n",
            "625\n",
            "\t -1 0.29649972666444047\n",
            "\t 0 0.2631174057921088\n",
            "\t 1 0.22645540682891918\n",
            "487\n",
            "\t -1 0.3273268353539886\n",
            "\t 0 0.12909944487358055\n",
            "\t 1 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEFZl8GkgVcs",
        "outputId": "ac25e7da-91c5-413b-9f88-86c19eb1c70a"
      },
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "# cos_sim = lambda x, y: dot(x,y)/(norm(x)*norm(y))\n",
        "cos_sim(text_vect, keyword_vect)\n",
        "cos_sim=np.dot(text_vect,keyword_vect)/(np.linalg.norm(text_vect)*np.linalg.norm(keyword_vect))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpSr0d-6hzfF",
        "outputId": "274be884-e052-42f4-bc4c-b716decd54bd"
      },
      "source": [
        "np.isfinite(keyword_vect).all()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRjG21qriCYQ",
        "outputId": "1ce9e945-dd8e-4ae7-c522-aca82cabfa70"
      },
      "source": [
        "np.isfinite(text_vect).all()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "ZKrlqzEbAkCJ",
        "outputId": "ed336fb8-ed73-4b1c-8756-40bd0a1f3cde"
      },
      "source": [
        "docs_df.head()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>547</td>\n",
              "      <td>love this phone however the sim card received did not work so had to go to verizon store to get new sim card</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>423</td>\n",
              "      <td>do not use cell phone lot but love the functionality of this phone it is more like mini tablet the pen that comes with it is very handy and activates the phone when you pull it out it is also great for more precise selections and for note taking am very happy with the resolution of the screen and the response of both touch and pen buying the phone from amazon and setting up new verizon account was painless easily got the account and on line payment set up without hitch also transferred my at phone number to the phone without any problems will not reiterate the tech specs of the phone as you can read all of that on the product page just want to let you know what think of it as user of the phone at this point in time could not be happier with this phone or the verizon service update have had this phone for little over years and still have no desire to get new phone did however recently decide to switch my service provider from verizon to mobile because of the offerings of mobile which will not get into was assured by the mobile rep that as long as the phone was unlocked could replace the verizon sim card with the one from mobile and the phone would work with no problems after activating the mobile sim card am updating this review so that others do not experience what did if they want to change their provider first of all verizon has never locked any of their phones verizon uses cdma network which is also used by sprint and us cellular mobile and at use gsm network one difference is the polarity used so phone for each type of network are manufactured to use the specific polarity of the network the other difference that should be considered by the end user is that on the gsm network customer information is stored on the sim card this means that you can take the sim card from one phone and insert it into another and it will work gsm carriers must accept any gsm phone so they do not have control over the phone you are using cdma carriers use network based white lists so you can only switch phones with your carrier permission and the carrier does not have to accept any particular phone there are other differences between the two network types but those have mentioned affect the end user the most in my case had to buy new phone in order to switch to mobile as carrier was also told by verizon that this phone may work with another cdma carrier but it my lose functionality have had to buy another phone to use the gsm network and have decided to get the galaxy note since have to give up my note hope this helps other in choosing carrier and phone</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>517</td>\n",
              "      <td>bought it as gift and she loves it large screen fast gets updates and since she plays lot of games on it it is exactly what she needs</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>626</td>\n",
              "      <td>when bought work fine but days stopped working you are going to waste your money the only good thing is that amazon helped me get my money back</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>794</td>\n",
              "      <td>phone arrived in time instructions to activate was very simple love my note sometimes have had issues with phone call quality but otherwise the phone is great buy love samsung products</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   row_id  ... label\n",
              "0     547  ...     1\n",
              "1     423  ...     0\n",
              "2     517  ...     0\n",
              "3     626  ...    -1\n",
              "4     794  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5Z-LNX1A8hl"
      },
      "source": [
        "def topic_sentence_similarity_score(sentence, topic, corpus):\n",
        "  t_vec = topic_vect_dict[topic]\n",
        "  s_vec = [1 if token in sentence.split() else 0 for token in corpus]\n",
        "  return cos_sim(s_vec, t_vec)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I0Hov-2C-v2",
        "outputId": "1668dd27-8ec2-4bad-dbba-fd1f47407742"
      },
      "source": [
        "docs_df['score'] = docs_df[['text', 'label']].apply(lambda row: topic_sentence_similarity_score(row['text'], row['label'], corpus), axis=1)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "lTLO4HCHaGnK",
        "outputId": "c3886ef9-1015-44dd-e607-b7ef8d1afef2"
      },
      "source": [
        "docs_df.sample(10)\n",
        "\n",
        "# row_id (721)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>721</td>\n",
              "      <td>concerned the product was sold as new and believe it is refurbished only had couple months and already having issues son mad at me yes he is an it and works on these he has note feels it was misrepresented</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>499</td>\n",
              "      <td>went through lot of extra trouble to get refurbished new note huge fan of the phone but am giving because for refurbished phone it will not even read micro sd card at all its missing pin connecter</td>\n",
              "      <td>1</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>658</td>\n",
              "      <td>one of the best android phones out there it only takes about half hour to charge and takes almost two days to be completely dead atleast that is how it is for me have had this phone for about four years jumping from phone service carrier to other phone service carriers and still enjoy it even though had repurchased it again when switching to different phone service provider because loved it so much if your looking for an electronic easy access hand notebook with efficient camera and strong battery this is great phone choice for you</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.534522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>766</td>\n",
              "      <td>this phone is great just matter of getting used to its capabilities overall no comparison to other phones in the market even the iphones the best phone out there period</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.534522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>449</td>\n",
              "      <td>thought this phone would be much faster but its no faster than my old phone the picture quality is ok just disappointed over all plus the seller sent me the wrong charger so had to go out and purchase one not satisfied customer</td>\n",
              "      <td>1</td>\n",
              "      <td>0.577350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>717</td>\n",
              "      <td>very good looking and solid phone almost like new no issues in the first months good price like it even more than the note that it replaced the screen is slightly bigger than the note screen</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.845154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>647</td>\n",
              "      <td>decided to wait utnil reviewed this phone we ordered four of these for our family and we have had them for five months now one of the phone had to be replaced after we got it because it would not hold charge so we got replacement for that one now after five months all four phones are having charging problems my wife phone will not charge anymore no matter what cord we use all other phones you have to jiggle the cord and have it placed in certain way to charge and then it takes way too long to charge this is an obvious manufacture defect one phone can understand but four phones or actually five if you count the one that was replaced that is unnaceptable and poor quality control and design on samsung part this will be the last samsung phone we buy it is unfortunate as the phone has great features but it does no good if you can not charge the phones properly so beware you could have battery charging problems after few months</td>\n",
              "      <td>-1</td>\n",
              "      <td>0.507093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>443</td>\n",
              "      <td>top dog imo best phone out there great for multitasking excellent screen fast lightweight camera takes great pictures in good lighting pen works great speaker output nice and crisp battery life really good if you turn off some un needed functions like gestures turn off gps when your not needing it turn off auto sync and set screen time out to sec been getting easy days without charging with light usage like streaming youtube web browsing and some email call quality very good can hear callers loud and sharp on verizon network that is blazing fast on verizon wifi antenna can be little stronger overall great phone by samsung</td>\n",
              "      <td>0</td>\n",
              "      <td>0.676123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>788</td>\n",
              "      <td>love my gn the screen is huge and beautiful so clear have only had it couple of weeks so still have much to learn no regrets</td>\n",
              "      <td>0</td>\n",
              "      <td>0.223607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>775</td>\n",
              "      <td>samsung is the best note is the best its not too big get an otterbox to protect sign up for class to learn all about it</td>\n",
              "      <td>0</td>\n",
              "      <td>0.447214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     row_id  ...     score\n",
              "195     721  ...  0.000000\n",
              "239     499  ...  0.333333\n",
              "48      658  ...  0.534522\n",
              "121     766  ...  0.534522\n",
              "119     449  ...  0.577350\n",
              "225     717  ...  0.845154\n",
              "86      647  ...  0.507093\n",
              "325     443  ...  0.676123\n",
              "212     788  ...  0.223607\n",
              "218     775  ...  0.447214\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    }
  ]
}